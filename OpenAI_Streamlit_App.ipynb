{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **An OpenAI Document Querying AI Tool - Streamlit App:**\n",
        "## **Utilising Large Lanaguage Models (LLMs), Chroma, OpenAI, Langchain and Streamlit.**\n",
        "\n",
        "This notebook will detail a Python project which will use OpenAI Large Language Models (LLMs) to allow users to receive answers to their questions on a long PDF document, via an LLM AI tool. This will be achieved through the use of Langchain, Chroma Vector Store, the OpenAI API and Streamlit libraries.   \n",
        "\n",
        "This notebook only contains the code required to run the streamlit app from a Google Colab notebook, which should have the CPU enabled.\n",
        "\n",
        "Ensure that the 25 page cycleguard insurance PDF document has been loaded into the notebook working directory before running the cells."
      ],
      "metadata": {
        "id": "cIEGcyfzW_Gh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-openai streamlit langchain-community pypdf chromadb\n",
        "!npm install localtunnel\n",
        "import urllib"
      ],
      "metadata": {
        "id": "K3OYxp2bWAxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8IQSYhDV_Ss",
        "outputId": "929a6175-bb47-497b-f318-f9cfda251f27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing openAI_streamlit_app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile openAI_streamlit_app.py\n",
        "\n",
        "import streamlit as st\n",
        "import os\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain_openai import OpenAI, OpenAIEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# Set OpenAI private API Key\n",
        "os.environ['OPENAI_API_KEY'] = 'your_private_OpenAI_API_key'\n",
        "\n",
        "# OpenAI text embedding model:\n",
        "text_embedding_model = OpenAIEmbeddings(model='text-embedding-ada-002')\n",
        "\n",
        "# Load the PDF document:\n",
        "input_document = PyPDFLoader('cycleGuard Policy Wording 2021-03.pdf') # Ensure this PDF document file has already been loaded into Colab working directory!\n",
        "# Split pages from the PDF\n",
        "pages = input_document.load_and_split()\n",
        "# Load documents into chroma embedding database:\n",
        "vector_store = Chroma.from_documents(pages, text_embedding_model, collection_name='cycle_insurance')\n",
        "\n",
        "# OpenAI LLM\n",
        "LLM = OpenAI(model='gpt-3.5-turbo-instruct', temperature=0.2)\n",
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
        "retrieval_QA_chain = RetrievalQA.from_chain_type(\n",
        "    llm=LLM,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    input_key = 'question')\n",
        "\n",
        "#-----------------Streamlit App Functionality----------------------#\n",
        "st.title('Using OpenAI LLMs to Answer Queries on an Insurance Document') # App title\n",
        "user_input = st.text_input('Enter your query here:') # User input box\n",
        "if user_input: # If user enters a query via the app interface, pass the query to OpenAI LLM\n",
        "    openAI_response = retrieval_QA_chain.invoke({\"question\": user_input})\n",
        "    st.write(openAI_response[\"result\"]) # Display the LLM response\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Password for localtunnel:\", urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))\n",
        "!streamlit run openAI_streamlit_app.py &>/content/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IDUDDIaWxB4",
        "outputId": "50d326e4-af50-449c-aad4-03cd625fd4a2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Password for localtunnel: 35.230.14.96\n",
            "35.230.14.96\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 3.649s\n",
            "your url is: https://forty-phones-sip.loca.lt\n"
          ]
        }
      ]
    }
  ]
}